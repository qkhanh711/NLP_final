{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web = req.get('https://vnexpress.net')\n",
    "\n",
    "S = bs(Web.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigator = S.find_all(class_='main-nav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newlest', 'thoisu', 'gocnhin', 'thegioi', 'podcasts', 'kinhdoanh', 'batdongsan', 'khoahoc', 'giaitri', 'thethao', 'phapluat', 'giaoduc', 'suckhoe', 'doisong', 'dulich', 'sohoa', 'xe', 'ykien', 'tamsu', 'cuoi']\n",
      "['/tin-tuc-24h', '/thoi-su', '/goc-nhin', '/the-gioi', '/podcast', '/kinh-doanh', '/bat-dong-san', '/khoa-hoc', '/giai-tri', '/the-thao', '/phap-luat', '/giao-duc', '/suc-khoe', '/doi-song', '/du-lich', '/so-hoa', '/oto-xe-may', '/y-kien', '/tam-su', '/thu-gian']\n"
     ]
    }
   ],
   "source": [
    "li_elements = navigator[0].find_all('li') \n",
    "classes = [li.get('class')[0] for li in li_elements][1:-1]\n",
    "paths = [li.find_all('a')[0].get('href') for li in li_elements][1:-1]\n",
    "\n",
    "classes.remove('video')\n",
    "paths.remove('https://video.vnexpress.net')\n",
    "\n",
    "print(classes)\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://vnexpress.net/tin-tuc-24h', 'https://vnexpress.net/thoi-su', 'https://vnexpress.net/goc-nhin', 'https://vnexpress.net/the-gioi', 'https://vnexpress.net/podcast', 'https://vnexpress.net/kinh-doanh', 'https://vnexpress.net/bat-dong-san', 'https://vnexpress.net/khoa-hoc', 'https://vnexpress.net/giai-tri', 'https://vnexpress.net/the-thao', 'https://vnexpress.net/phap-luat', 'https://vnexpress.net/giao-duc', 'https://vnexpress.net/suc-khoe', 'https://vnexpress.net/doi-song', 'https://vnexpress.net/du-lich', 'https://vnexpress.net/so-hoa', 'https://vnexpress.net/oto-xe-may', 'https://vnexpress.net/y-kien', 'https://vnexpress.net/tam-su', 'https://vnexpress.net/thu-gian']\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://vnexpress.net' + content for content in paths]\n",
    "print(urls)\n",
    "\n",
    "def get_text(url):\n",
    "    Web = req.get(url)\n",
    "\n",
    "    S = bs(Web.text, 'lxml')\n",
    "    return {\"HTML code\": S.prettify(),\n",
    "            \"List articles' links\": S.find_all('article', {'data-offset': True})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_page = get_text(urls[0])\n",
    "# print(home_page[\"HTML code\"])\n",
    "# print(\n",
    "# home_page[\"List articles' links\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list article's links of cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://vnexpress.net/tranh-the-beatles-ve-gia-hon-1-7-trieu-usd-4709013.html',\n",
       " 'https://vnexpress.net/co-nen-ban-nha-dat-de-mua-chung-cu-4704454.html',\n",
       " 'https://vnexpress.net/nam-australia-dung-nhan-hoc-sinh-ba-tinh-cua-viet-nam-4709069.html',\n",
       " 'https://vnexpress.net/dan-quan-than-iran-tap-kich-can-cu-my-o-syria-4709044.html',\n",
       " 'https://vnexpress.net/thu-tuong-dieu-chinh-gia-dien-phu-hop-thi-truong-khong-giat-cuc-4709038.html',\n",
       " 'https://vnexpress.net/6-loai-nam-ngu-coc-phong-ung-thu-vu-4708793.html',\n",
       " 'https://vnexpress.net/nghi-pham-phi-tang-thi-the-nguoi-nuoc-ngoai-o-phan-thiet-la-ai-4709007.html',\n",
       " 'https://vnexpress.net/112-nguoi-chet-trong-dot-chay-rung-toi-te-nhat-tai-chile-4709040.html',\n",
       " 'https://vnexpress.net/nguoi-dan-khap-the-gioi-trang-tri-chuan-bi-don-tet-4708806.html',\n",
       " 'https://vnexpress.net/ben-trong-nha-hang-chay-thuc-duong-giua-long-tp-hcm-4708324.html',\n",
       " 'https://vnexpress.net/moi-nguy-suc-khoe-tu-mon-ca-phe-pha-ot-4708942.html',\n",
       " 'https://vnexpress.net/gia-tri-cua-mot-gia-dinh-hanh-phuc-4709048.html',\n",
       " 'https://vnexpress.net/trinh-chinh-phu-tang-luong-toi-thieu-tu-ngay-1-7-4708996.html',\n",
       " 'https://vnexpress.net/ong-duterte-muon-dao-que-nha-ly-khai-khoi-philippines-4708923.html',\n",
       " 'https://vnexpress.net/5-mon-an-uong-nen-han-che-truoc-khi-len-may-bay-4708862.html',\n",
       " 'https://vnexpress.net/me-chong-lien-tuc-muon-su-dung-tien-cua-toi-4708460.html',\n",
       " 'https://vnexpress.net/mua-nha-vinhomes-tra-gop-15-trieu-dong-moi-thang-4708994.html',\n",
       " 'https://vnexpress.net/bi-quyet-an-uong-giam-can-nhanh-don-tet-4708945.html',\n",
       " 'https://vnexpress.net/gap-lai-chi-bau-mo-man-gan-9-ty-dong-4708989.html',\n",
       " 'https://vnexpress.net/truc-thang-mi-8-nga-roi-xuong-ho-4708976.html',\n",
       " 'https://vnexpress.net/cho-vay-duoi-5-trieu-dong-voi-tam-ly-mat-luon-tien-4708987.html',\n",
       " 'https://vnexpress.net/thieu-nu-nga-tu-lau-5-thoat-tay-tu-than-4708924.html',\n",
       " 'https://vnexpress.net/volkswagen-noi-gian-vi-dai-ly-duc-nhap-xe-dien-tu-trung-quoc-4708763.html',\n",
       " 'https://vnexpress.net/dong-tuyen-tim-ban-doi-4708951.html',\n",
       " 'https://vnexpress.net/nhung-chuyen-tau-xe-mien-phi-dua-cong-nhan-ve-tet-4708959.html',\n",
       " 'https://vnexpress.net/neville-carragher-tin-man-city-vo-dich-ngoai-hang-anh-4708946.html',\n",
       " 'https://vnexpress.net/bung-no-doanh-thu-ban-ao-dai-mua-tet-4708659.html',\n",
       " 'https://vnexpress.net/mat-ma-tiep-vien-dung-am-chi-hanh-khach-tren-may-bay-4700340.html',\n",
       " 'https://vnexpress.net/runner-doat-ve-du-olympic-ngay-lan-dau-chay-marathon-4708978.html',\n",
       " 'https://vnexpress.net/khoanh-khac-nga-trut-7-bom-dan-duong-xuong-nha-may-ukraine-4708873.html']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = home_page[\"List articles' links\"]\n",
    "# for article in articles:\n",
    "#     print(article.find('h3').text)\n",
    "#     print(article.find('p').text)\n",
    "#     print(article.find('a')['href'])\n",
    "#     print()\n",
    "    # print()\n",
    "\n",
    "list_to_crawl = [article.find('a')['href'] for article in articles]\n",
    "list_to_crawl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl data\n",
    "\n",
    "Title:\n",
    "\n",
    "Source:\n",
    "\n",
    "Link:\n",
    "\n",
    "Published Date:\n",
    "\n",
    "Author:\n",
    "\n",
    "Tags:\n",
    "\n",
    "Summary:\n",
    "\n",
    "Content:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawler(list_to_crawl, num_clusters=1):\n",
    "    for clusID in range(num_clusters):\n",
    "        for i in range(len(list_to_crawl)):\n",
    "            url = list_to_crawl[i]\n",
    "            soup = bs(req.get(url).text, 'lxml')\n",
    "            title = soup.find('title').text\n",
    "            # print(f\"Title: {title}\")\n",
    "            source = soup.find('meta', {'name': 'author'})['content']\n",
    "            # print(f\"Source: {source}\")\n",
    "            # print(f\"Link: {url}\")\n",
    "            published_date = soup.find('span', class_='date').text\n",
    "            # print(f\"Published Date: {published_date}\")\n",
    "            author = ''\n",
    "            content = ''\n",
    "            for p in soup.find_all('p'):\n",
    "                if p.get('style') == 'text-align:right;':\n",
    "                    author = p.text\n",
    "                else:\n",
    "                    content += p.text\n",
    "            # print(f\"Author: {author}\")\n",
    "            tags = soup.find('meta', {'name': 'keywords'})['content']\n",
    "            # print(f\"Tags: {tags}\")\n",
    "            summary = soup.find('meta', {'property': 'og:description'})['content']\n",
    "            # print(f\"Summary: {summary}\")\n",
    "            # print(f\"Content: {content}\")\n",
    "            # print()\n",
    "            import os\n",
    "            if not os.path.exists(f'vnexpress_data/original/Cluster_{clusID+1:03}/original'):\n",
    "                os.makedirs(f'vnexpress_data/original/Cluster_{clusID+1:03}/original')\n",
    "            with open(f'vnexpress_data/original/Cluster_{clusID+1:03}/original/{i+1}.txt ', 'a') as f:\n",
    "                f.write(f\"Title: {title}\\n\")\n",
    "                f.write(f\"Source: {source}\\n\")\n",
    "                f.write(f\"Link: {url}\\n\")\n",
    "                f.write(f\"Published Date: {published_date}\\n\")\n",
    "                f.write(f\"Author: {author}\\n\")\n",
    "                f.write(f\"Tags: {tags}\\n\")\n",
    "                f.write(f\"Summary: {summary}\\n\")\n",
    "                f.write(f\"Content: {content}\\n\\n\")\n",
    "crawler(list_to_crawl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_page = get_text(urls[0])\n",
    "pages = [get_text(url) for url in urls]\n",
    "def saveCluster(pages):\n",
    "    for i in range(len(pages)):\n",
    "        articles = pages[i][\"List articles' links\"]\n",
    "        list_to_crawl = [article.find('a')['href'] for article in articles]\n",
    "        crawler(list_to_crawl, num_clusters=len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m saveCluster(pages)\n",
      "Cell \u001b[0;32mIn[106], line 7\u001b[0m, in \u001b[0;36msaveCluster\u001b[0;34m(pages)\u001b[0m\n\u001b[1;32m      5\u001b[0m articles \u001b[38;5;241m=\u001b[39m pages[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList articles\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m links\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m list_to_crawl \u001b[38;5;241m=\u001b[39m [article\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m articles]\n\u001b[0;32m----> 7\u001b[0m crawler(list_to_crawl, num_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(pages))\n",
      "Cell \u001b[0;32mIn[105], line 5\u001b[0m, in \u001b[0;36mcrawler\u001b[0;34m(list_to_crawl, num_clusters)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(list_to_crawl)):\n\u001b[1;32m      4\u001b[0m     url \u001b[38;5;241m=\u001b[39m list_to_crawl[i]\n\u001b[0;32m----> 5\u001b[0m     soup \u001b[38;5;241m=\u001b[39m bs(req\u001b[38;5;241m.\u001b[39mget(url)\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     title \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# print(f\"Title: {title}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed()\n\u001b[1;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mfeed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkup)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/builder/_lxml.py:378\u001b[0m, in \u001b[0;36mLXMLTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser_for(encoding)\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mfeed(markup)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mLookupError\u001b[39;00m, etree\u001b[38;5;241m.\u001b[39mParserError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32msrc/lxml/parser.pxi:1259\u001b[0m, in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parser.pxi:1379\u001b[0m, in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parsertarget.pxi:168\u001b[0m, in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parsertarget.pxi:156\u001b[0m, in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:334\u001b[0m, in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/saxparser.pxi:443\u001b[0m, in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/saxparser.pxi:458\u001b[0m, in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parsertarget.pxi:94\u001b[0m, in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bs4/builder/_lxml.py:289\u001b[0m, in \u001b[0;36mLXMLTreeBuilderForXML.start\u001b[0;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Namespaces are in play. Find any attributes that came in\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# from lxml with namespaces attached to their names, and\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# turn then into NamespacedAttribute objects.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m new_attrs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(attrs\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m    290\u001b[0m     namespace, attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getNsTag(attr)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saveCluster(pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
